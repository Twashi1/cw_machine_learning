{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.io as sio\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_root = os.path.join('./data', 'ThingsEEG-Text')\n",
    "sbj = 'sub-10'\n",
    "image_model = 'pytorch/cornet_s'\n",
    "text_model = 'CLIPText'\n",
    "roi = '17channels'\n",
    "brain_dir = os.path.join(data_dir_root, 'brain_feature', roi, sbj)\n",
    "image_dir_seen = os.path.join(data_dir_root, 'visual_feature/ThingsTrain', image_model, sbj)\n",
    "image_dir_unseen = os.path.join(data_dir_root, 'visual_feature/ThingsTest', image_model, sbj)\n",
    "text_dir_seen = os.path.join(data_dir_root, 'textual_feature/ThingsTrain/text', text_model, sbj)\n",
    "text_dir_unseen = os.path.join(data_dir_root, 'textual_feature/ThingsTest/text', text_model, sbj)\n",
    "\n",
    "# TODO: this is already doing some feature scaling it seems\n",
    "brain_seen = sio.loadmat(os.path.join(brain_dir, 'eeg_train_data_within.mat'))['data'].astype('double') * 2.0\n",
    "brain_seen = brain_seen[:,:,27:60] # 70ms-400ms\n",
    "brain_seen = np.reshape(brain_seen, (brain_seen.shape[0], -1))\n",
    "image_seen = sio.loadmat(os.path.join(image_dir_seen, 'feat_pca_train.mat'))['data'].astype('double')*50.0\n",
    "text_seen = sio.loadmat(os.path.join(text_dir_seen, 'text_feat_train.mat'))['data'].astype('double')*2.0\n",
    "label_seen = sio.loadmat(os.path.join(brain_dir, 'eeg_train_data_within.mat'))['class_idx'].T.astype('int')\n",
    "image_seen = image_seen[:,0:100]\n",
    "\n",
    "brain_unseen = sio.loadmat(os.path.join(brain_dir, 'eeg_test_data.mat'))['data'].astype('double')*2.0\n",
    "brain_unseen = brain_unseen[:, :, 27:60]\n",
    "brain_unseen = np.reshape(brain_unseen, (brain_unseen.shape[0], -1))\n",
    "image_unseen = sio.loadmat(os.path.join(image_dir_unseen, 'feat_pca_test.mat'))['data'].astype('double')*50.0\n",
    "text_unseen = sio.loadmat(os.path.join(text_dir_unseen, 'text_feat_test.mat'))['data'].astype('double')*2.0\n",
    "label_unseen = sio.loadmat(os.path.join(brain_dir, 'eeg_test_data.mat'))['class_idx'].T.astype('int')\n",
    "image_unseen = image_unseen[:, 0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: proper credit\n",
    "# https://medium.com/@koushikkushal95/logistic-regression-from-scratch-dfb8527a4226\n",
    "# https://stackoverflow.com/questions/67513075/what-is-c-parameter-in-sklearn-logistic-regression\n",
    "class CustomLogisticRegression:\n",
    "    def __init__(self, learning_rate : float = 0.1, threshold : float = 0.5, regularization_strength : float = 1.0):\n",
    "        self.epsilon = 1e-9\n",
    "        self.learning_rate = learning_rate\n",
    "        self.threshold = threshold\n",
    "        self.weights = None\n",
    "        self.bias = 0.0\n",
    "        self.regularization_strength = 1.0 / regularization_strength if regularization_strength != 0.0 else 0.0\n",
    "    \n",
    "    def predict_probability(self, x : np.ndarray) -> np.ndarray:\n",
    "        x_dot_weights = np.dot(x, self.weights) + self.bias\n",
    "        probabilities = self._sigmoid(x_dot_weights)\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "    def predict(self, x : np.ndarray) -> np.ndarray:\n",
    "        prediction = self.predict_probability(x)\n",
    "        return np.where(prediction > self.threshold, 1, 0)\n",
    "\n",
    "    # Returns losses and log likelihoods\n",
    "    def fit(self, x_train, y_train, epochs=100) -> tuple[np.ndarray, np.ndarray]:\n",
    "        # Weights on each feature\n",
    "        self.weights = np.zeros(x_train.shape[1])\n",
    "        self.bias = 0.0\n",
    "        \n",
    "        losses = np.zeros((epochs,))\n",
    "        log_likelihood = np.zeros((epochs,))\n",
    "\n",
    "        # Gradient Descent\n",
    "        for i in range(epochs):\n",
    "            prediction = self.predict_probability(x_train)\n",
    "            losses[i] = self._cross_entropy_loss(y_train, prediction)\n",
    "            log_likelihood[i] = self._log_likelihood(x_train, y_train)\n",
    "            error_weights, error_bias = self._compute_gradients(x_train, y_train, prediction)\n",
    "            self._update_parameters(error_weights, error_bias)\n",
    "\n",
    "        return losses, log_likelihood\n",
    "\n",
    "    @staticmethod\n",
    "    def _sigmoid(x : np.ndarray) -> np.ndarray:\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "    \n",
    "    def _cross_entropy_loss(self, y_true : np.ndarray, y_pred : np.ndarray) -> float:\n",
    "        # Binary cross entropy loss\n",
    "        y_zero_loss = y_true * np.log(y_pred + self.epsilon)\n",
    "        y_one_loss = (1.0 - y_true) * np.log(1.0 - y_pred + self.epsilon)\n",
    "\n",
    "        return -np.mean(y_zero_loss + y_one_loss)\n",
    "\n",
    "    def _log_likelihood(self, x : np.ndarray, y : np.ndarray) -> float:\n",
    "        penalty = self.regularization_strength * np.sum(self.weights ** 2.0)\n",
    "        scores = np.dot(x, scores)\n",
    "\n",
    "        return np.sum((y - 1.0) * scores - np.log(1.0 + np.exp(-scores))) - penalty\n",
    "\n",
    "    def _compute_gradients(self, x : np.ndarray, y_true : np.ndarray, y_pred : np.ndarray) -> tuple[np.ndarray, float]:\n",
    "        diff = y_pred - y_true\n",
    "        penalty = 2.0 * self.regularization_strength * self.weights\n",
    "\n",
    "        gradients_weights = (1.0 / x.shape[0]) * (np.dot(x.T, diff)) - penalty\n",
    "        gradient_bias = (1.0 / x.shape[0]) * np.sum(diff)\n",
    "\n",
    "        return gradients_weights, gradient_bias\n",
    "\n",
    "    def _update_parameters(self, error_weights : np.ndarray, error_bias : float) -> None:\n",
    "        self.weights -= self.learning_rate * error_weights\n",
    "        self.bias -= self.learning_rate * error_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OvR and OvO classifiers\n",
    "\n",
    "# Process the data such that one class is highlighted in each instance of the data\n",
    "#   get the resulting output vector, pick maximum probability\n",
    "class OneVsRest:\n",
    "    def __init__(self, model_constructor, num_classes : int, use_probability : bool = True):\n",
    "        self.models = [model_constructor() for _ in range(num_classes)]\n",
    "        self.num_classes = num_classes\n",
    "        self.use_probability = use_probability\n",
    "\n",
    "    def fit(self, x_train : np.ndarray, y_train : np.ndarray, epochs : int = 100) -> tuple[np.ndarray, np.ndarray]:\n",
    "        total_loss = np.zeros((len(self.models), epochs))\n",
    "        total_log_likelihood = np.zeros((len(self.models), epochs))\n",
    "\n",
    "        for class_number, model in enumerate(self.models):\n",
    "            # Get the binary version of the data\n",
    "            #   label the current class as positive, and all other classes\n",
    "            #   as negative\n",
    "            y_ovr = np.where(y_train == class_number, 1.0, 0.0)\n",
    "            loss, log_likelihood = model.fit(x_train, y_ovr, epochs=epochs)\n",
    "\n",
    "            total_loss[class_number, :] += loss\n",
    "            total_log_likelihood[class_number, :] += log_likelihood\n",
    "\n",
    "        return total_loss.mean(axis=0), total_log_likelihood.mean(axis=0)\n",
    "\n",
    "    def predict(self, x : np.ndarray) -> np.ndarray:\n",
    "        # Get a prediction from every model\n",
    "        #   each prediction is a probability from 0-1 for each instance\n",
    "        #       (or just the predicted class if we're not using probability)\n",
    "        #   arrange these into a matrix\n",
    "        #   get the argmax from every column of the matrix\n",
    "        #   consider that to be the class\n",
    "        matrix = np.zeros((x.shape[0], self.num_classes))\n",
    "\n",
    "        for class_number, model in enumerate(self.models):\n",
    "            votes = model.predict_probability(x) if self.use_probability else model.predict(x)\n",
    "            matrix[:, class_number] = votes\n",
    "\n",
    "        predicted_classes = np.argmax(matrix, axis=1)\n",
    "        \n",
    "        return predicted_classes\n",
    "\n",
    "class OneVsOne:\n",
    "    def __init__(self, model_constructor, num_classes : int, use_probability : bool = True):\n",
    "        self.num_classes = num_classes\n",
    "        self.models = [model_constructor() for _ in range((num_classes * (num_classes - 1)) // 2)]\n",
    "        self.use_probability = use_probability\n",
    "\n",
    "    def fit(self, x_train : np.ndarray, y_train : np.ndarray, epochs : int = 100) -> tuple[np.ndarray, np.ndarray]:\n",
    "        idx = 0\n",
    "\n",
    "        total_loss = np.zeros((len(self.models), epochs))\n",
    "        total_log_likelihood = np.zeros((len(self.models), epochs))\n",
    "\n",
    "        for class_pos in range(self.num_classes):\n",
    "            for class_neg in range(class_pos + 1, self.num_classes):\n",
    "                model = self.models[idx]\n",
    "\n",
    "                # Filter out classes not in one of the classes\n",
    "                class_mask = ((y_train == class_pos) | (y_train == class_neg))\n",
    "\n",
    "                x_ovo = x_train[class_mask]\n",
    "                # Mark positive class as 1, negative class as 0\n",
    "                y_ovo = np.where(y_train[class_mask] == class_pos, 1.0, 0.0)\n",
    "\n",
    "                # Train\n",
    "                loss, log_likelihood = model.fit(x_ovo, y_ovo, epochs=epochs)\n",
    "\n",
    "                total_loss[idx, :] += loss\n",
    "                total_log_likelihood[idx, :] += log_likelihood\n",
    "\n",
    "                idx += 1\n",
    "\n",
    "        return total_loss.mean(axis=0), total_log_likelihood.mean(axis=0)\n",
    "\n",
    "    def predict(self, x : np.ndarray) -> np.ndarray:\n",
    "        # Each model votes on one class\n",
    "        #   class with most votes is selected\n",
    "        #   note very similar to OvR,\n",
    "        #       but each model votes on only the positive/negative instances\n",
    "        #       instead of all instances\n",
    "        idx = 0\n",
    "\n",
    "        votes_matrix = np.zeros((x.shape[0], self.num_classes))\n",
    "\n",
    "        for class_pos in range(self.num_classes):\n",
    "            for class_neg in range(class_pos + 1, self.num_classes):\n",
    "                model = self.models[idx]\n",
    "\n",
    "                # On each instance, determine if it was positive/negative\n",
    "                #   vote for that class\n",
    "                votes = model.predict_probability(x) if self.use_probability else model.predict(x)\n",
    "\n",
    "                votes_matrix[:, class_pos] += votes\n",
    "                votes_matrix[:, class_neg] += 1.0 - votes\n",
    "\n",
    "                idx += 1\n",
    "\n",
    "        return np.argmax(votes_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various train/test splits\n",
    "SAMPLES_PER_CLASS = 10\n",
    "\n",
    "# Only sampling from seen data\n",
    "def train_test_split(num_classes : int = 50, split_percentage : float = 0.7):\n",
    "    split_index = math.ceil(SAMPLES_PER_CLASS * split_percentage)\n",
    "\n",
    "    # All instances where the seen class is within the classes we want\n",
    "    seen_classes_filter = np.squeeze(label_seen <= num_classes)\n",
    "    # unseen_classes_filter = np.squeeze(label_unseen <= num_classes)\n",
    "\n",
    "    # Filter modalities to get only instances with the allowed classes\n",
    "    brain_seen_reduced = brain_seen[seen_classes_filter]\n",
    "    image_seen_reduced = image_seen[seen_classes_filter]\n",
    "    text_seen_reduced = text_seen[seen_classes_filter]\n",
    "    label_seen_reduced = label_seen[seen_classes_filter]\n",
    "\n",
    "    # brain_unseen_reduced = brain_unseen[unseen_classes_filter]\n",
    "    # image_unseen_reduced = image_unseen[unseen_classes_filter]\n",
    "    # text_unseen_reduced = text_unseen[unseen_classes_filter]\n",
    "    # label_unseen_reduced = label_unseen[unseen_classes_filter]\n",
    "\n",
    "    brain_features = brain_seen.shape[1]\n",
    "    image_features = image_seen.shape[1]\n",
    "    text_features = text_seen.shape[1]\n",
    "\n",
    "    # Per class number of training/test examples\n",
    "    num_training = split_index\n",
    "    num_test = SAMPLES_PER_CLASS - split_index\n",
    "\n",
    "    def split_data(seen_instances : np.ndarray, num_features : int) -> tuple[np.ndarray, np.ndarray]:\n",
    "        train_out = np.zeros((num_training * num_classes, num_features))\n",
    "        test_out = np.zeros((num_test * num_classes, num_features))\n",
    "\n",
    "        for i in range(num_classes):\n",
    "            curr = seen_instances[i * SAMPLES_PER_CLASS:(i + 1) * SAMPLES_PER_CLASS, :]\n",
    "            train_data = curr[:split_index, :]\n",
    "            test_data = curr[split_index:, :]\n",
    "\n",
    "            train_out[i * num_training:(i + 1) * num_training, :] = train_data\n",
    "            test_out[i * num_test:(i + 1) * num_test, :] = test_data\n",
    "\n",
    "        return train_out, test_out\n",
    "\n",
    "    brain_train, brain_test = split_data(brain_seen_reduced, brain_features)\n",
    "    image_train, image_test = split_data(image_seen_reduced, image_features)\n",
    "    text_train, text_test = split_data(text_seen_reduced, text_features)\n",
    "    label_train, label_test = split_data(label_seen_reduced, 1)\n",
    "\n",
    "    # 0-indexing is more convenient for OvR/OvO\n",
    "    #   also ensure label dimensions are 1d array\n",
    "    label_train = label_train.squeeze() - 1\n",
    "    label_test = label_test.squeeze() - 1\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"Modality\": [\"Brain\", \"Image\", \"Text\", \"Label\"],\n",
    "        \"Train\": [brain_train, image_train, text_train, label_train],\n",
    "        \"Test\": [brain_test, image_test, text_test, label_test]\n",
    "    })\n",
    "\n",
    "def get_data_from_train_test(dataframe : pd.DataFrame, modality : str, type : str):\n",
    "    modality_index = dataframe.index[dataframe[\"Modality\"]==modality]\n",
    "    return dataframe.loc[modality_index, type].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "def normal_scale_features(x : np.ndarray) -> np.ndarray:\n",
    "    out = np.zeros(x.shape)\n",
    "\n",
    "    for feature in range(x.shape[1]):\n",
    "        feature_vector = x[:, feature]\n",
    "\n",
    "        std = feature_vector.std()\n",
    "        mean = feature_vector.mean()\n",
    "\n",
    "        out[:, feature] = (feature_vector - mean) / std\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter instances with too many outliers in them\n",
    "# Returns truth series, where False represents an outlier\n",
    "#   any row contains more than 10% outliers, discard it, represents a bad instance\n",
    "def outlier_mask(x : np.ndarray, tolerance : float = 0.1) -> np.ndarray:\n",
    "    out = np.zeros(x.shape)\n",
    "\n",
    "    for feature in range(x.shape[1]):\n",
    "        feature_vector = x[:, feature]\n",
    "        # Calculate IQR\n",
    "        lb = np.quantile(feature_vector.squeeze(), 0.25).item()\n",
    "        ub = np.quantile(feature_vector.squeeze(), 0.75).item()\n",
    "        iqr = ub - lb\n",
    "        whisker_length = 1.5  # in reference to the histogram whisker length\n",
    "\n",
    "        out[:, feature] = ~((feature_vector < (lb - whisker_length * iqr)) | (feature_vector > (ub + whisker_length * iqr)))\n",
    "\n",
    "    instance_filter = np.zeros(x.shape[0])\n",
    "\n",
    "    for instance in range(x.shape[0]):\n",
    "        instance_filter[instance] = out[instance, :].mean() > (1.0 - tolerance)\n",
    "\n",
    "    return instance_filter.astype(np.bool)\n",
    "# TODO: strip noisy features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all combinations of modalities\n",
    "BRAIN_BIT = 1\n",
    "TEXT_BIT = 2\n",
    "IMAGE_BIT = 3\n",
    "\n",
    "all_modalities = pd.DataFrame({\n",
    "    \"Combination\": [\"Brain\", \"Text\", \"Image\", \"BrainText\", \"BrainImage\", \"TextImage\", \"All\"],\n",
    "    \"Bitmap\": [BRAIN_BIT, TEXT_BIT, IMAGE_BIT, BRAIN_BIT | TEXT_BIT, BRAIN_BIT | IMAGE_BIT, TEXT_BIT | IMAGE_BIT, BRAIN_BIT | TEXT_BIT | IMAGE_BIT]\n",
    "})\n",
    "\n",
    "def get_combined_data(brain_data : np.ndarray, text_data : np.ndarray, image_data : np.ndarray, bitmap : int) -> np.ndarray:\n",
    "    modalities_data = []\n",
    "\n",
    "    if bitmap & BRAIN_BIT:\n",
    "        modalities_data.append(brain_data)\n",
    "    if bitmap & TEXT_BIT:\n",
    "        modalities_data.append(text_data)\n",
    "    if bitmap & IMAGE_BIT:\n",
    "        modalities_data.append(image_data)\n",
    "\n",
    "    return np.hstack(tuple(modalities_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some baseline parameters for future testing of other features\n",
    "from sklearn.linear_model import LogisticRegression  # Baseline sklearn model\n",
    "\n",
    "# Create a baseline train/test split, and extract training dataset and testing dataset\n",
    "BASELINE_NUM_CLASSES = 50\n",
    "BASELINE_TRAIN_TEST_SPLIT = 0.7\n",
    "\n",
    "BASELINE_SPLIT_DATA = train_test_split(BASELINE_NUM_CLASSES, BASELINE_TRAIN_TEST_SPLIT)\n",
    "\n",
    "baseline_data_train = get_data_from_train_test(BASELINE_SPLIT_DATA, \"Brain\", \"Train\")\n",
    "baseline_data_test = get_data_from_train_test(BASELINE_SPLIT_DATA, \"Brain\", \"Test\")\n",
    "BASELINE_LABEL_TRAIN = get_data_from_train_test(BASELINE_SPLIT_DATA, \"Label\", \"Train\")\n",
    "BASELINE_LABEL_TEST = get_data_from_train_test(BASELINE_SPLIT_DATA, \"Label\", \"Test\")\n",
    "\n",
    "# Perform standard scaling on data\n",
    "BASELINE_DATA_TRAIN = normal_scale_features(baseline_data_train)\n",
    "BASELINE_DATA_TEST = normal_scale_features(baseline_data_test)\n",
    "\n",
    "# Standard hyperparameters\n",
    "BASELINE_LEARNING_RATE = 0.1\n",
    "BASELINE_THRESHOLD = 0.5\n",
    "BASELINE_REGULARIZATION = 1.0\n",
    "BASELINE_CUSTOM_MODEL = lambda: CustomLogisticRegression(BASELINE_LEARNING_RATE, BASELINE_THRESHOLD, BASELINE_REGULARIZATION)\n",
    "BASELINE_USE_PROBABILITY = True\n",
    "BASELINE_MUTLICLASS = OneVsRest(BASELINE_CUSTOM_MODEL, BASELINE_NUM_CLASSES, BASELINE_USE_PROBABILITY)\n",
    "BASELINE_SKLEARN_MODEL = LogisticRegression(penalty=\"l2\", multi_class=\"ovr\", C=1.0, max_iter=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1.\n",
    "#   vary train test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'zeroes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[402], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m logistic_model_constructor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: CustomLogisticRegression(\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     41\u001b[0m ovr \u001b[38;5;241m=\u001b[39m OneVsRest(logistic_model_constructor, BASELINE_NUM_CLASSES)\n\u001b[0;32m---> 42\u001b[0m losses_ovr, log_likelihood_ovr \u001b[38;5;241m=\u001b[39m \u001b[43movr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m ovr_pred \u001b[38;5;241m=\u001b[39m ovr\u001b[38;5;241m.\u001b[39mpredict(test_features)\n\u001b[1;32m     45\u001b[0m ovo \u001b[38;5;241m=\u001b[39m OneVsOne(logistic_model_constructor, BASELINE_NUM_CLASSES)\n",
      "Cell \u001b[0;32mIn[395], line 20\u001b[0m, in \u001b[0;36mOneVsRest.fit\u001b[0;34m(self, x_train, y_train, epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_number, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Get the binary version of the data\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#   label the current class as positive, and all other classes\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#   as negative\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     y_ovr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(y_train \u001b[38;5;241m==\u001b[39m class_number, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     loss, log_likelihood \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_ovr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     total_loss[class_number, :] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     23\u001b[0m     total_log_likelihood[class_number, :] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m log_likelihood\n",
      "Cell \u001b[0;32mIn[391], line 30\u001b[0m, in \u001b[0;36mCustomLogisticRegression.fit\u001b[0;34m(self, x_train, y_train, epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     29\u001b[0m losses \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((epochs,))\n\u001b[0;32m---> 30\u001b[0m log_likelihood \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeroes\u001b[49m((epochs,))\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Gradient Descent\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n",
      "File \u001b[0;32m~/Coding/ml_model_cw/cw_machine_learning/venv/lib/python3.12/site-packages/numpy/__init__.py:414\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchar\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m char\u001b[38;5;241m.\u001b[39mchararray\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'zeroes'"
     ]
    }
   ],
   "source": [
    "# TODO: to remove\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# brain_train_outliers = outlier_mask(brain_train)\n",
    "# brain_test_outliers = outlier_mask(brain_test)\n",
    "\n",
    "# label_train_outliers = label_train[brain_train_outliers]\n",
    "# label_test_outliers = label_test[brain_test_outliers]\n",
    "\n",
    "# print(label_train.shape)\n",
    "# print(label_test.shape)\n",
    "# print(label_train_outliers.shape)\n",
    "# print(label_test_outliers.shape)\n",
    "\n",
    "# brain_train_scaled = normal_scale_features(brain_train[brain_train_outliers])\n",
    "# brain_test_scaled = normal_scale_features(brain_test[brain_test_outliers])\n",
    "\n",
    "all_train = get_combined_data(\n",
    "    get_data_from_train_test(BASELINE_SPLIT_DATA, \"Brain\", \"Train\"),\n",
    "    get_data_from_train_test(BASELINE_SPLIT_DATA, \"Text\", \"Train\"),\n",
    "    get_data_from_train_test(BASELINE_SPLIT_DATA, \"Image\", \"Train\"),\n",
    "    BRAIN_BIT | TEXT_BIT | IMAGE_BIT\n",
    ")\n",
    "all_test = get_combined_data(\n",
    "    get_data_from_train_test(BASELINE_SPLIT_DATA, \"Brain\", \"Test\"),\n",
    "    get_data_from_train_test(BASELINE_SPLIT_DATA, \"Text\", \"Test\"),\n",
    "    get_data_from_train_test(BASELINE_SPLIT_DATA, \"Image\", \"Test\"),\n",
    "    BRAIN_BIT | TEXT_BIT | IMAGE_BIT\n",
    ")\n",
    "\n",
    "all_train_scaled = normal_scale_features(all_train)\n",
    "all_test_scaled = normal_scale_features(all_test)\n",
    "\n",
    "train_features = BASELINE_DATA_TRAIN\n",
    "test_features = BASELINE_DATA_TEST\n",
    "train_labels = BASELINE_LABEL_TRAIN\n",
    "test_labels = BASELINE_LABEL_TEST\n",
    "\n",
    "# Note threshold parameter doesn't affect OvR since OvR uses probabilities\n",
    "logistic_model_constructor = lambda: CustomLogisticRegression(0.01, 0.5, 1.0)\n",
    "ovr = OneVsRest(logistic_model_constructor, BASELINE_NUM_CLASSES)\n",
    "losses_ovr, log_likelihood_ovr = ovr.fit(train_features, train_labels, 100)\n",
    "ovr_pred = ovr.predict(test_features)\n",
    "\n",
    "ovo = OneVsOne(logistic_model_constructor, BASELINE_NUM_CLASSES)\n",
    "ovo.fit(train_features, train_labels, 100)\n",
    "ovo_pred = ovo.predict(test_features)\n",
    "\n",
    "model = LogisticRegression(multi_class=\"ovr\", max_iter=100, random_state=0, penalty=\"l2\", C=1.0)\n",
    "model.fit(train_features, train_labels)\n",
    "sk_pred = model.predict(test_features)\n",
    "\n",
    "def get_stats(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    diverse_stats = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\", zero_division=0.0)\n",
    "\n",
    "    return accuracy, diverse_stats[0], diverse_stats[1], diverse_stats[2]\n",
    "\n",
    "ovo_stats = get_stats(test_labels, ovo_pred)\n",
    "ovr_stats = get_stats(test_labels, ovr_pred)\n",
    "base_stats = get_stats(test_labels, sk_pred)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Classifier\": [\"OvO\", \"OvR\", \"Baseline\"],\n",
    "    \"Accuracy\": [ovo_stats[0], ovr_stats[0], base_stats[0]],\n",
    "    \"Precision\": [ovo_stats[1], ovr_stats[1], base_stats[1]],\n",
    "    \"Recall\": [ovo_stats[2], ovr_stats[2], base_stats[2]],\n",
    "    \"F1-Score\": [ovo_stats[3], ovr_stats[3], base_stats[3]]\n",
    "})\n",
    "\n",
    "losses_df = pd.DataFrame({\n",
    "    \"Epoch\": list(range(100)),\n",
    "    \"Loss\": losses_ovr,\n",
    "    \"LogLikelihood\": log_likelihood_ovr\n",
    "})\n",
    "\n",
    "long_df = df.melt(\"Classifier\", var_name=\"ScoreType\", value_name=\"Score\")\n",
    "\n",
    "sns.barplot(long_df, x=\"Classifier\", y=\"Score\", hue=\"ScoreType\")\n",
    "sns.lineplot(losses_df, x=\"Epoch\", y=\"Loss\")\n",
    "sns.lineplot(losses_df, x=\"Epoch\", y=\"LogLikelihood\")\n",
    "\n",
    "# TODO: grid search hyperparameters (likely little effect, but can test learning rate, convergence, and regularization)\n",
    "# TODO: compare between only brain/text/image, and the other combinations of modalities\n",
    "# TODO: we have very few samples per class compared to number of classes, making this a good candidate for\n",
    "#   a few-shot learning paradigm\n",
    "# TODO: why did we choose logistic regression\n",
    "# TODO: training/validation procedure\n",
    "#   why OvR better than OvO?\n",
    "#   test various test/train splits and their impact on performance\n",
    "#   \n",
    "# TODO: plot loss/log likelihood throughout training\n",
    "# TODO: plot final test performance across multiple statistics\n",
    "# TODO: improve the model (using multiple modalities, using few-shot learning paradigm, using feature scaling, using regularization, using SGD - most likely)\n",
    "# TODO: clear explanation of accuracy, precision, recall, f1-score (likely already have, maybe in context of comparison between baseline and custom)\n",
    "# TODO: use confusion matrices and precision-recall curves (can we even do this for multiclass?)\n",
    "# TODO: the problem identified in 2.1 is the small number of samples per class, we fixed this with the few-shot learning paradigm\n",
    "\n",
    "# TODO: few-shot learning uses a similarity function, that learns from the small set of training data\n",
    "#   this is basically just the same as logistic regression??! or any learning model??!\n",
    "#   one-way to implement FSL is data-level, incorporate more features through some method (we can do this by combining modalities)\n",
    "#   regularization is one way to fix FSL, limiting parameter values to prevent overfitting\n",
    "#   metric-level FSL?\n",
    "#   https://www.digitalocean.com/community/tutorials/few-shot-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
